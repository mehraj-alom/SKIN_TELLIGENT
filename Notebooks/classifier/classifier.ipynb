{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Disease Image Classification Project\n",
    "\n",
    "This notebook presents a deep learning approach for **classifying skin diseases from images**. The key objectives of this project are to build an accurate and efficient model while managing computational resources and training time.\n",
    "\n",
    "## Dataset and Classes\n",
    "The original dataset contained multiple classes of skin diseases. To **reduce training time and complexity**, we have **merged/reduced the number of classes**. This helps the model learn more generalized patterns, avoids overfitting on underrepresented classes, and speeds up experimentation.\n",
    "\n",
    "## Preprocessing\n",
    "- Image resizing and normalization to standardize inputs.\n",
    "- Data augmentation (like rotations, flips, and color adjustments) to improve model generalization.\n",
    "- Splitting into training, validation, and test sets to evaluate performance properly.\n",
    "\n",
    "## Model and Hyperparameter Tuning\n",
    "We have implemented a deep learning classifier using convolutional neural networks (CNNs). To **optimize model performance**, we performed **hyperparameter tuning using Optuna**:\n",
    "- Optuna efficiently searches for the best hyperparameters by exploring different combinations and pruning underperforming trials.\n",
    "- Parameters tuned include learning rate, batch size, optimizer type, dropout rates, and number of layers/neurons.\n",
    "- The **best parameters** were selected based on validation performance to improve accuracy while reducing overfitting.\n",
    "\n",
    "## Key Decisions\n",
    "1. **Class Reduction:** Reduced the number of classes to manage training time and computational cost, while maintaining clinically meaningful categories.\n",
    "2. **Optuna Hyperparameter Tuning:** Allowed efficient identification of the best hyperparameters without exhaustive search.\n",
    "3. **Data Augmentation:** Improved generalization and model robustness on unseen data.\n",
    "\n",
    "This setup ensures a balance between **model performance, training efficiency, and interpretability**, making it suitable for practical deployment in skin disease detection workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents a deep learning approach for classifying skin diseases from images. The main objective of this project is to build an accurate and efficient model while managing computational resources and training time.\n",
    "\n",
    "The original dataset contained multiple classes of skin diseases. To reduce complexity and improve training efficiency, the number of classes was reduced. This decision allowed the model to focus on learning generalized patterns and avoid overfitting on underrepresented classes.\n",
    "\n",
    "The model was trained multiple times using Kaggle, and the process was time-consuming. Initial attempts yielded a low F1 score of 0.23. To improve performance, **Optuna** was used for hyperparameter tuning, optimizing parameters such as learning rate, batch size, optimizer type, dropout rates, and network architecture. After multiple training cycles and fine-tuning, the F1 score improved significantly from **0.23 to 0.70**.\n",
    "\n",
    "Although the current model achieves a respectable F1 score of 0.70, there is room for further improvement. In future iterations, I plan to build a more advanced model and continue hyperparameter tuning, with the goal of increasing the F1 score to **0.85–0.90**. This will involve experimenting with different architectures, fine-tuning training strategies, and systematically optimizing model parameters to achieve higher accuracy and reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T17:34:35.578584Z",
     "iopub.status.busy": "2025-09-26T17:34:35.578132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "sd20co001_image_dataset_for_skindiseases_dry_oily_normalskin_path = kagglehub.dataset_download('sd20co001/image-dataset-for-skindiseases-dry-oily-normalskin')\n",
    "\n",
    "print(\"Data source import complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sd20co001/image-dataset-for-skindiseases-dry-oily-normalskin\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install optuna -q\n",
    "!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader , Dataset , random_split , WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm # progress bars\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import timm\n",
    "import math\n",
    "from ast import Pass\n",
    "import time\n",
    "import copy\n",
    "from collections import Counter\n",
    "from optuna.pruners import MedianPruner # early stopping for bad trials.\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna # hyperparameter tuning engine\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import wandb\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/kaggle/input/image-dataset-for-skindiseases-dry-oily-normalskin\"\n",
    "\n",
    "\n",
    "image_paths = glob.glob(ROOT_DIR + \"/**/*.jpg\",recursive=True)\n",
    "image_paths += glob.glob(ROOT_DIR + \"/**/*.jpeg\",recursive=True)\n",
    "image_paths += glob.glob(ROOT_DIR + \"/**/*.png\",recursive=True)\n",
    "df = pd.DataFrame({\n",
    "    \"image_path\" : image_paths,\n",
    "    \"label\" : [os.path.basename(os.path.dirname(p)) for p in image_paths]\n",
    "})\n",
    "print(\"Total images:\", len(df))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "keep_labels = [\n",
    "    \"Acne\",\n",
    "    \"Nail Fungus And Other Nail Disease\",\n",
    "    \"Vitiligo\",\n",
    "    \"Rosacea\",\n",
    "    \"Rashes\",\n",
    "    \"Shingles\",\n",
    "    \"Skin_Cancer_Malignant\",\n",
    "    \"Psoriasis_Pictures_Lichen_Planus_And_Related_Diseases\",\n",
    "    \"Fungal_Infections_Ringworm_Candidiasis\",\n",
    "    \"Atopic_Dermatitis\",\n",
    "    \"Eczema\",\n",
    "    \"Herpes\",\n",
    "    \"Warts\",\n",
    "    \"Dermatitis\",\n",
    "    \"Actinic keratosis\",\n",
    "    \"Benign_Tumors_Keratoses\",\n",
    "    \"Chickenpox\",\n",
    "    \"Dermatofibroma\",\n",
    "    \"Dry_Skin\",\n",
    "    \"Hidradenitis-Suppurativa\",\n",
    "    \"Lupus_And_Other_Connective_Tissue_Diseases\",\n",
    "    \"Oily_Skin\",\n",
    "    \"Urticaria_Hives\",\n",
    "    \"Light_Diseases_And_Disorders_Of_Pigmentation\",\n",
    "    \"Bullous_Disease_Photos\",\n",
    "    \"Hair_Loss_Photos_Alopecia_And_Other_Hair_Diseases\",\n",
    "    \"Poison_Ivy_Photos_And_Other_Contact_Dermatitis\",\n",
    "    \"Other diseases\",\n",
    "    \"Pa_Cutaneous_Larva_Migrans\",\n",
    "    \"Exanthems_And_Drug_Eruptions\"\n",
    "]\n",
    "\n",
    "# Filter dataset\n",
    "df = df[df['label'].isin(keep_labels)].reset_index(drop=True)\n",
    "df.to_csv(\"filtered_dataset.csv\", index=False)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Label_Map = {\n",
    "    \"Cellulitis_Impetigo_And_Other_Bacterial_Infections\": \"Bacterial_Infections_Cellulitis_Impetigo\",\n",
    "    \"Ba_Cellulitis\": \"Bacterial_Infections_Cellulitis_Impetigo\",\n",
    "    \"Ba_Impetigo\": \"Bacterial_Infections_Cellulitis_Impetigo\",\n",
    "\n",
    "    \"Ringworm\": \"Fungal_Infections_Ringworm_Candidiasis\",\n",
    "    \"Athlete_Foot\": \"Fungal_Infections_Ringworm_Candidiasis\",\n",
    "    \"Tinea_Ringworm_Candidiasis_And_Other_Fungal_Infections\": \"Fungal_Infections_Ringworm_Candidiasis\",\n",
    "\n",
    "    \"Seborrheic_Keratoses_And_Other_Benign_Tumors\": \"Benign_Tumors_Keratoses\",\n",
    "    \"Benign_Tumors\": \"Benign_Tumors_Keratoses\",\n",
    "    \"Benign_Keratosis\": \"Benign_Tumors_Keratoses\",\n",
    "\n",
    "    \"Malignant_Tumors\": \"Skin_Cancer_Malignant\",\n",
    "    \"Malignant_Lesions\": \"Skin_Cancer_Malignant\",\n",
    "    \"Basal_Cell_Carcinoma_and_Other_Carcinoma\": \"Skin_Cancer_Malignant\",\n",
    "    \"Melanoma_Skin_Cancer_Nevi_And_Moles\": \"Skin_Cancer_Malignant\",\n",
    "\n",
    "    \"Actinic_Keratosis\": \"Actinic_Keratosis_And_Cheilitis\",\n",
    "    \"Actinic_Cheilitis\": \"Actinic_Keratosis_And_Cheilitis\",\n",
    "}\n",
    "print(f\"Lebel_counts_before_marging : {df.label.nunique()}\")\n",
    "df[\"label\"] = df.label.replace(Label_Map)\n",
    "print(f\"Lebel_counts_AFTER_marging : {df.label.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    " # Saving The new CSV file\n",
    "CSV_PATH = \"skin_dataset.csv\"\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(\"New_df_saved>>....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df[\"image_path\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_temp , y_train , y_temp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.25,\n",
    "    stratify = y ,\n",
    "    random_state = 23\n",
    ")\n",
    "\n",
    "X_val , X_test , y_val , y_test = train_test_split(\n",
    "    X_temp ,\n",
    "    y_temp,\n",
    "    test_size = 0.5,\n",
    "    stratify = y_temp,\n",
    "    random_state = 23\n",
    ")\n",
    "print(f\"Train ; {X_train.shape} , Test : {X_test.shape} , Val : {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    v2.Resize((380,380)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ColorJitter(brightness = 0.2,\n",
    "                  contrast = 0.2,\n",
    "                  saturation = 0.3),\n",
    "    v2.RandomVerticalFlip(p = 0.5),\n",
    "    v2.RandomRotation(25),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(imagenet_mean,\n",
    "                imagenet_std)\n",
    "])\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.Resize((380,380)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(imagenet_mean,imagenet_std)\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((380,380)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale= True),\n",
    "    v2.Normalize(imagenet_mean,\n",
    "                imagenet_std)\n",
    "])\n",
    "print(f\"train {train_transform} , val : {val_transform} , test : {test_transform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    \"image_path\" : X_train,\n",
    "    \"label\" : y_train\n",
    "})\n",
    "val_df = pd.DataFrame({\n",
    "    \"image_path\" : X_val,\n",
    "    \"label\" : y_val\n",
    "})\n",
    "test_df = pd.DataFrame({\n",
    "    \"image_path\" : X_test,\n",
    "    \"label\" : y_test\n",
    "})\n",
    "\n",
    "SAVE_DIR = \"/kaggle/working/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(os.path.join(SAVE_DIR , \"train.csv\") , index = False)\n",
    "val_df.to_csv(os.path.join(SAVE_DIR, \"val.csv\") , index = False)\n",
    "test_df.to_csv(os.path.join(SAVE_DIR , \"test.csv\") , index = False)\n",
    "\n",
    "print(f\"Saved train.csv, val.csv, test.csv in {SAVE_DIR}\")\n",
    "print(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_labels = sorted(train_df[\"label\"].unique())\n",
    "cls_to_idx = {label : idx for idx , label in enumerate(all_labels)}\n",
    "\n",
    "class_counts = train_df[\"label\"].value_counts().to_dict()\n",
    "counts = np.array([class_counts.get(label, 0) for label in all_labels])\n",
    "\n",
    "# Class-Balanced Loss Based on Effective Number of Samples (CVPR 2019).\n",
    "beta = 0.9999\n",
    "effective_num = 1.0 - np.power(beta, counts)\n",
    "weights = (1.0 - beta) / effective_num\n",
    "weights = weights / np.sum(weights)\n",
    "\n",
    "# Convert to tensor for PyTorch\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "sample_weights = [class_weights[cls_to_idx[label]] for label in train_df[\"label\"]]\n",
    "\n",
    "# diyctionary for reference\n",
    "normalized_weights = {\n",
    "    cls: w for cls, w in zip(class_counts.keys(), weights)\n",
    "}\n",
    "\n",
    "print(\"✅ Class-balanced Weights:\")\n",
    "for k, v in normalized_weights.items():\n",
    "    print(f\"{k}: {v:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SKINDISEASE(Dataset):\n",
    "    def __init__(self,df, transforms = None , label_dict = None):\n",
    "        self.data = df\n",
    "        self.transforms = transforms\n",
    "        self.label_dict = label_dict\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.data.iloc[idx][\"image_path\"]\n",
    "        label = self.data.iloc[idx][\"label\"]\n",
    "\n",
    "        if self.label_dict:\n",
    "            label = self.label_dict[label]\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms :\n",
    "            img = self.transforms(img)\n",
    "        return img , label # WHY ?? int(label) -> Look at the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = SKINDISEASE(\n",
    "    df = train_df,\n",
    "    transforms = train_transform,\n",
    "    label_dict = cls_to_idx\n",
    ")\n",
    "val_dataset = SKINDISEASE(\n",
    "    df = val_df ,\n",
    "    transforms = val_transform ,\n",
    "    label_dict = cls_to_idx\n",
    ")\n",
    "test_dataset = SKINDISEASE(\n",
    "    df = test_df,\n",
    "    transforms = test_transform ,\n",
    "    label_dict = cls_to_idx\n",
    ")\n",
    "display(train_dataset , val_dataset , test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "                          dataset = train_dataset,\n",
    "                          batch_size=32,\n",
    "                          sampler=sampler,\n",
    "                          num_workers = 2,\n",
    "                          pin_memory = True)\n",
    "val_dataloader = DataLoader(\n",
    "                          dataset = val_dataset ,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = False,\n",
    "                          num_workers = 2,\n",
    "                          pin_memory = True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "                          dataset = test_dataset ,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = False,\n",
    "                          num_workers = 2,\n",
    "                          pin_memory = True\n",
    ")\n",
    "print(f\"Train_dataloader length : {len(train_dataloader)}  | test_data_loader : {len(val_dataloader)} Test DataLoader length : {len(test_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(len(cls_to_idx)) == (train_df[\"label\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(cls_to_idx)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_model(name ,\n",
    "             num_classes ,\n",
    "             pretrained = True,\n",
    "             device = \"cuda\"):\n",
    "    if name.startswith(\"efficientnet_b\"):\n",
    "        if pretrained:\n",
    "            # Correctly specify the weight enum\n",
    "            if name == \"efficientnet_b2\":\n",
    "                weights = models.EfficientNet_B2_Weights.IMAGENET1K_V1\n",
    "            # Added similar conditions for other efficientnet_b models if needed\n",
    "            else:\n",
    "                 weights = None # Or handle other efficientnet versions\n",
    "\n",
    "            model = getattr(models , name)(weights=weights)\n",
    "        else:\n",
    "            model = getattr(models , name)(weights=None) # Pass weights=None for non-pretrained\n",
    "        if hasattr(model , \"classifier\") :\n",
    "            if isinstance (model.classifier , nn.Sequential) and isinstance(model.classifier[-1] , nn.Linear):\n",
    "                in_f = model.classifier[-1].in_features\n",
    "                model.classifier[-1] = nn.Linear(in_f , num_classes)\n",
    "\n",
    "            else :\n",
    "                in_f = model.classifier.in_features\n",
    "                model.classifier = nn.Linear(in_f , num_classes)\n",
    "\n",
    "    elif name == \"densenet121\" :\n",
    "        model = models.densenet121(weights = models.DenseNet121_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        in_f = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(in_f , num_classes)\n",
    "    elif name == \"resnet50\" :\n",
    "        model = models.resnet50(weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        in_f = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_f , num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model : {name}\")\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model,\n",
    "                   dataloader,\n",
    "                   loss_fn,\n",
    "                   optimizer,\n",
    "                   device,\n",
    "                   scheduler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds , all_labels = [] , []\n",
    "\n",
    "    loop = tqdm(dataloader,desc=\"Train\", leave=False) # Used leave=False to remove the bar after completion\n",
    "    for images , labels in loop :\n",
    "        images , labels = images.to(device) , labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler and isinstance(scheduler,OneCycleLR):\n",
    "            scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = torch.argmax(outputs , dim = 1).detach().cpu().numpy()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    return avg_loss , all_labels , all_preds\n",
    "\n",
    "def validate(model ,\n",
    "            dataloader ,\n",
    "            loss_fn ,\n",
    "            device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels , all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(dataloader,desc=\"Val\", leave=False) \n",
    "        for images , labels in loop :\n",
    "            images , labels = images.to(device) , labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs , labels)\n",
    "\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(outputs, dim = 1).detach().cpu().numpy()\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "        avg_loss = running_loss / len(dataloader.dataset)\n",
    "        return avg_loss , all_labels , all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_labels_from_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Try to detect labels list for common dataset types (ImageFolder, custom).\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(dataset , \"targets\"):\n",
    "        return list(dataset.targets)\n",
    "    if hasattr(dataset,\"labels\"):\n",
    "        return list(dataset.labels)\n",
    "    if hasattr(dataset,\"samples\"):\n",
    "        return [label for _, label in dataset.samples]\n",
    "\n",
    "    labels = []\n",
    "    # Assuming the dataset returns (image, label) pairs\n",
    "    for _, lbl in dataset:\n",
    "        labels.append(int(lbl))\n",
    "    return labels\n",
    "\n",
    "def get_weighted_sampler(dataset):\n",
    "    labels = get_labels_from_dataset(dataset)\n",
    "    class_counts = Counter(labels)\n",
    "    num_samples = len(labels)\n",
    "    weights = [1.0 / class_counts[lbl] for lbl in labels]\n",
    "    sampler = WeightedRandomSampler(weights,\n",
    "                                   num_samples = num_samples,\n",
    "                                   replacement = True)\n",
    "    return sampler\n",
    "\n",
    "def get_macro_f1(y_true, y_pred , num_classes):\n",
    "    return f1_score(y_true,y_pred,average=\"macro\",labels=list(range(num_classes)))\n",
    "\n",
    "def load_model(model_path, model_name, num_classes, device):\n",
    "    \"\"\"Loads a pre-trained model from a specified path.\"\"\"\n",
    "    model = get_model(model_name, num_classes, pretrained=False, device=device)\n",
    "    # Load the entire checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    # Extract the model state dictionary\n",
    "    model_state_dict = checkpoint.get('model_state', checkpoint) # Used to get with a default for flexibility\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    \"\"\"Makes predictions on a dataset.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            all_preds.extend(preds.tolist())\n",
    "    return all_preds\n",
    "\n",
    "def evaluate(y_true, y_pred, all_labels):\n",
    "    \"\"\"Evaluates predictions and displays classification report and confusion matrix.\"\"\"\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=all_labels))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=all_labels, yticklabels=all_labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def final_retrain_and_save(best_params, train_dataset, val_dataset, num_classes,\n",
    "                           class_weights, device, epochs=30, batch_size=32, save_path=\"best_model.pth\"):\n",
    "\n",
    "    train_sampler = get_weighted_sampler(train_dataset)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = get_model(best_params.get(\"model_name\", \"efficientnet_b2\"), num_classes=num_classes,\n",
    "                      pretrained=True, device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "    opt_name = best_params.get(\"optimizer\", \"AdamW\")\n",
    "    lr = best_params.get(\"lr\", 1e-3)\n",
    "    wd = best_params.get(\"weight_decay\", 1e-4)\n",
    "\n",
    "    if opt_name == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    else:\n",
    "        momentum = best_params.get(\"momentum\", 0.9)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
    "\n",
    "    scheduler = None\n",
    "    sched_name = best_params.get(\"scheduler\", \"OneCycleLR\")\n",
    "    if sched_name == \"OneCycleLR\":\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "    elif sched_name == \"CosineAnnealingLR\":\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    elif sched_name == \"ReduceLROnPlateau\":\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
    "\n",
    "    best_val = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, _, _ = train_one_epoch(model, train_loader, criterion, optimizer, device, scheduler)\n",
    "        val_loss, y_true, y_pred = validate(model, val_loader, criterion, device)\n",
    "        macro_f1 = get_macro_f1(y_true, y_pred, num_classes)\n",
    "        print(f\"[Final Retrain] Epoch {epoch+1}/{epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f} | F1: {macro_f1:.4f}\")\n",
    "\n",
    "        if macro_f1 > best_val:\n",
    "            best_val = macro_f1\n",
    "            torch.save({\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"params\": best_params,\n",
    "                \"epoch\": epoch,\n",
    "                \"val_macro_f1\": best_val\n",
    "            }, save_path)\n",
    "            print(f\" Saved best model to {save_path} (F1={best_val:.4f})\")\n",
    "\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Best params <- from optuna study [To access the notebook : https://colab.research.google.com/drive/1UcBeG6IA-Zgt8tLCUnwqSTBzIKiuha4a?usp=sharing]\n",
    "best_params = {\n",
    "    \"model_name\" : \"efficientnet_b2\",\n",
    "    \"optimizer\" : \"AdamW\",\n",
    "    \"lr\" : 2.96e-04,\n",
    "    \"weight_decay\" : 8.23e-04,\n",
    "    \"scheduler\" : None,\n",
    "    \"batch_size\" : 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_dataset_full = train_dataloader.dataset\n",
    "    val_dataset_full = val_dataloader.dataset\n",
    "\n",
    "    \n",
    "    # num_classes = len(cls_to_idx)\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    # print(\"11\")\n",
    "    # train_df_reduced = get_balanced_subset_df(train_df, n_per_class=120, seed=42)\n",
    "    # print(\"train_loaded\")\n",
    "    # val_df_reduced   = get_balanced_subset_df(val_df, n_per_class=30, seed=123)\n",
    "    # print(\"val_loaded\")\n",
    "    # train_dataset_reduced = SKINDISEASE(\n",
    "    #     df = train_df_reduced,\n",
    "    #     transforms = train_transform,\n",
    "    #     label_dict = cls_to_idx\n",
    "    # )\n",
    "    # val_dataset_reduced = SKINDISEASE(\n",
    "    #     df = val_df_reduced ,\n",
    "    #     transforms = val_transform ,\n",
    "    #     label_dict = cls_to_idx\n",
    "    # )\n",
    "\n",
    "\n",
    "    # study = run_optuna_study(train_dataset_reduced, val_dataset_reduced, num_classes, class_weights_tensor,\n",
    "    #                          device, n_trials=20, epochs=3,\n",
    "    #                          study_name=\"skin_hpo_production\",\n",
    "    #                          storage=\"sqlite:///optuna_skin.db\", use_wandb=True)\n",
    "\n",
    "    # best_params = study.best_trial.params1`\n",
    "    saved_path = final_retrain_and_save(best_params, train_dataset, val_dataset,\n",
    "                                        num_classes, class_weights, device,\n",
    "                                        epochs=15,\n",
    "                                        batch_size=best_params.get(\"batch_size\", 24),\n",
    "                                        save_path=\"best_skin_model.pth\")\n",
    "    print(\"Final saved model:\", saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/working/best_skin_model.pth\" \n",
    "best_model_name = \"efficientnet_b2\" \n",
    "num_classes = len(cls_to_idx)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "all_labels = sorted(cls_to_idx.keys()) \n",
    "\n",
    "try:\n",
    "    model = load_model(model_path, best_model_name, num_classes, device)\n",
    "    print(f\"Model loaded successfully from {model_path}\")\n",
    "\n",
    "    y_true_test = [label for _, label in test_dataset]\n",
    "\n",
    "    y_pred_test = predict(model, test_dataloader, device)\n",
    "\n",
    "    evaluate(y_true_test, y_pred_test, all_labels)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {model_path}. Please make sure the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7873693,
     "isSourceIdPinned": false,
     "sourceId": 12478967,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 456363,
     "modelInstanceId": 439812,
     "sourceId": 588250,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
